{
  "metadata": {
    "name": "P3",
    "kernelspec": {
      "language": "scala",
      "name": "spark2-scala"
    },
    "language_info": {
      "codemirror_mode": "text/x-scala",
      "file_extension": ".scala",
      "mimetype": "text/x-scala",
      "name": "scala",
      "pygments_lexer": "scala"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2,
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": "\u003cimg src\u003d\"https://i.ibb.co/9yHYrrB/2020-07-15.jpg\" alt\u003d\"2020-07-15\" border\u003d\"0\"\u003e\n\u003cimg src\u003d\"https://i.ibb.co/pWvz8hV/2020-07-15-1.png\" alt\u003d\"2020-07-15-1\" border\u003d\"0\"\u003e"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": "https://www.postgresqltutorial.com/"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": "\u003cli\u003eWe have already created empty Database with the name \u003cb\u003e\u0027ioadatabase\u0027\u003c/b\u003e in AWS (us-east-1) by loggin into AWS Console.\u003c/li\u003e\n\u003cli\u003eThe Database details for connection are given below. \u003c/li\u003e\n\u003cli\u003eIn the following steps we will connect and create tables in the Database.\u003c/li\u003e"
    },
    {
      "cell_type": "raw",
      "metadata": {
        "format": "text/plain"
      },
      "source": "%pyspark\r\n\r\nimport psycopg2\r\n\r\nENDPOINT\u003d\"mydbinstance.c3dm5owknewm.us-east-1.rds.amazonaws.com\" #Relational Database Service (Amazon RDS) endpoint.  Incase of local DB use \u0027localhost\u0027 or \u0027127.0.0.1\u0027\r\nPORT\u003d\"5432\" #Default Port number used at the time of creation of PostgreSQL service running in AWS\r\nDBNAME\u003d\"ioadatabase\" #Database name used at the time of creation of DB\r\nUSR\u003d\"ioausa\" #Database Master username used at the time of creation of DB\r\nPWD\u003d\"my-db-pass\" #Database Master password used at the time of creation of DB\r\n\r\ntry:\r\n    conn \u003d psycopg2.connect(host\u003dENDPOINT, port\u003dPORT, database\u003dDBNAME, user\u003dUSR, password\u003dPWD)\r\n    cur \u003d conn.cursor()\r\n    cur.execute(\"\"\"SELECT now()\"\"\") #Confirming the connection\r\n    query_results \u003d cur.fetchall()\r\n    print(query_results)\r\nexcept Exception as e:\r\n    print(\"Database connection failed due to {}\".format(e))  "
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": "\u003cli\u003eCREATE - INSERT\u003c/li\u003e\n\u003cli\u003eREAD\u003c/li\u003e\n\u003cli\u003eUPDATE\u003c/li\u003e\n\u003cli\u003eDELETE\u003c/li\u003e"
    },
    {
      "cell_type": "raw",
      "metadata": {
        "format": "text/plain"
      },
      "source": "%pyspark\n\ncur.execute(\"\"\"drop table if exists public.\"MOVIES\";\n                create table public.\"MOVIES\"(\n                MOVIE_ID integer primary key,\n                TITLE text,\n                GENRES text)\"\"\")\n\nwith open(\u0027/downloads/ml-latest-small/movies.txt\u0027, \u0027r\u0027) as f: #File path looks like linux filesytem because Zeppelin is running under Docker linux container setup.\n    f.readline() # Skip the header row\n    cur.copy_from(f, \u0027public.\"MOVIES\"\u0027, sep\u003d\u0027\\t\u0027, null\u003d\"\")\n\nconn.commit()\n\n# Printing first 5 rows\ncur.execute(\"\"\"SELECT * FROM public.\"MOVIES\" LIMIT 5\"\"\")\ncur.fetchall()"
    },
    {
      "cell_type": "raw",
      "metadata": {
        "format": "text/plain"
      },
      "source": "%pyspark\n\ncur.execute(\"\"\"drop table if exists public.\"LINKS\";\n                create table public.\"LINKS\"(\n                MOVIE_ID integer primary key,\n                IMDB_ID integer,\n                TMDB_ID integer)\"\"\")\n\nwith open(\u0027/downloads/ml-latest-small/links.txt\u0027, \u0027r\u0027) as f:\n    f.readline() # Skip the header row\n    cur.copy_from(f, \u0027public.\"LINKS\"\u0027, sep\u003d\u0027\\t\u0027, null\u003d\"\")\n\nconn.commit()\n\n# Printing first 5 rows\ncur.execute(\"\"\"SELECT * FROM public.\"LINKS\" LIMIT 5\"\"\")\ncur.fetchall()"
    },
    {
      "cell_type": "raw",
      "metadata": {
        "format": "text/plain"
      },
      "source": "%pyspark\n\ncur.execute(\"\"\"drop table if exists public.\"RATINGS\";\n                create table public.\"RATINGS\"(\n                USER_ID integer,\n                MOVIE_ID integer,\n                RATING float,\n                TIMESTAMP text)\"\"\")\n\nwith open(\u0027/downloads/ml-latest-small/ratings.txt\u0027, \u0027r\u0027) as f:\n    f.readline() # Skip the header row\n    cur.copy_from(f, \u0027public.\"RATINGS\"\u0027, sep\u003d\u0027\\t\u0027, null\u003d\"\")\n\nconn.commit()\n\n# Printing first 5 rows\ncur.execute(\"\"\"SELECT * FROM public.\"RATINGS\" LIMIT 5\"\"\")\ncur.fetchall()"
    },
    {
      "cell_type": "raw",
      "metadata": {
        "format": "text/plain"
      },
      "source": "%pyspark\n\ncur.execute(\"\"\"drop table if exists public.\"TAGS\";\n                create table public.\"TAGS\"(\n                USER_ID integer,\n                MOVIE_ID integer,\n                TAG text,\n                TIMESTAMP text)\"\"\")\n\nwith open(\u0027/downloads/ml-latest-small/tags.txt\u0027, \u0027r\u0027) as f:\n    f.readline() # Skip the header row\n    cur.copy_from(f, \u0027public.\"TAGS\"\u0027, sep\u003d\u0027\\t\u0027)\n\nconn.commit()\n\n# Printing first 5 rows\ncur.execute(\"\"\"select * from public.\"TAGS\" limit 5\"\"\")\ncur.fetchall()"
    },
    {
      "cell_type": "raw",
      "metadata": {
        "format": "text/plain"
      },
      "source": "%pyspark\n\nquery \u003d \"\"\" insert into public.\"MOVIES\" (MOVIE_ID, TITLE, GENRES) values (%s,%s,%s)\"\"\"\nrecord_to_insert \u003d ( \u00271000000\u0027 , \u0027Once Upon a Time... in Hollywood (2019)\u0027,  \u0027Comedy|Drama\u0027)\ncur.execute(query, record_to_insert)\n\nconn.commit()\ncount \u003d cur.rowcount\nprint (count, \"Record inserted successfully into MOVIES table\")"
    },
    {
      "cell_type": "raw",
      "metadata": {
        "format": "text/plain"
      },
      "source": "%pyspark\n\nprint(\"Table Before updating record \")\nquery \u003d \"\"\"select * from public.\"MOVIES\" where MOVIE_ID \u003d %s\"\"\"\ncur.execute(query, (1000000, ))\nrecord \u003d cur.fetchone()\nprint(record)\n\n# Update single record now\nquery \u003d \"\"\"Update public.\"MOVIES\" set TITLE \u003d %s where MOVIE_ID \u003d %s\"\"\"\ncur.execute(query, (\u0027Once Upon a Time in Hollywood (2019)\u0027, 1000000))\nconn.commit()\ncount \u003d cur.rowcount\nprint(count, \"Record Updated successfully \")\n\nprint(\"Table After updating record \")\nquery \u003d \"\"\"select * from public.\"MOVIES\" where MOVIE_ID \u003d %s\"\"\"\ncur.execute(query, (1000000,))\nrecord \u003d cur.fetchone()\nprint(record)"
    },
    {
      "cell_type": "raw",
      "metadata": {
        "format": "text/plain"
      },
      "source": "%pyspark\n\nquery \u003d \"\"\" delete from public.\"MOVIES\" where MOVIE_ID \u003d %s\"\"\"\ncur.execute(query, (1000000,))\n\nconn.commit()\ncount \u003d cur.rowcount\nprint(count, \"Record deleted successfully \")"
    },
    {
      "cell_type": "raw",
      "metadata": {
        "format": "text/plain"
      },
      "source": "%pyspark\n\nquery \u003d \"\"\" select * from public.\"MOVIES\" where MOVIE_ID \u003d %s \"\"\"\ncur.execute(query, (1000000,))\n\ncur.fetchall()"
    },
    {
      "cell_type": "raw",
      "metadata": {
        "format": "text/plain"
      },
      "source": "%pyspark\n"
    }
  ]
}